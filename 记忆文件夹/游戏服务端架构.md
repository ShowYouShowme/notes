# 第一章 绪论

本文主要收集笔者多年游戏开发中常用的服务器的架构。

除了connector 和client保持长连接，上游服务之间不要建立长连接，断线重连的问题会变得非常麻烦。



# 第二章 基于消息队列的服务架构



## 2.1 采用消息队列Rabbitmq

```
connector1

connector2   ------>  Rabbitmq  --------->  Game

connectorN
```

1. Rabbitmq有两个队列，一个队列存放client的请求，一个队列存放Game推送给client的数据

2. connector的数据结构

   ```protobuf
   enum ConnectCMD{
   	NONE	 = 0;
   	OPEN 	 = 1;
   	MESSAGE  = 2;
   	CLOSE    = 3;
   	ERROR    = 4;
   }
   
   
   message ConnectMessage{
   	int32 sID 		= 1;   //每个Connector 启动时都有一个唯一的serverID; 可以RPC某个服务获取
   	int32 cID 		= 2;   // 每个客户端连接都有一个cID
   	ConnectCMD cmd  = 3;
   	bytes 	 data   = 4;
   }
   ```

3. Game 模拟skynet的做法，把全部的服务写到 一个进程里面，每个服务使用一个线程。





## 2.2 采用zeromq

zmq的好处是不需要处理连接的重连、不用管服务启动次序等

1. 推荐架构：connector 是发布者，上游服务是订阅者。connector收到client请求时，发布消息，上游服务过滤后处理！上游服务器需要推送消息给client时，采用push--pull模式（connector是单节点）。

   ```
                                --------------> login(subscribe login)
   
   connector --publish-->       ---------------> game(subscribe game)
   
                                ----------------> store(subscribe store)
   
                                -----------------> task(subscribe task)
                                
                                
   # 推送消息时
   
   connector  <---(pull)--          <-----push-----   game
   ```

   

2. 架构一：connector收到client数据用PIPE模式 push给 Game； 每个connector都订阅Game的消息，当Game需要主动推送消息给client，利用ZMQ.PUB

   ```
   connector1 PUSH ----->
   
   connector2 PUSH -----> PULL  GAME
   
   connector3 PUSH ----->
   ```

3. 架构二：和架构一相比，有一个专门的push 服务；每个connector多监听一个ZMQ.REP 端口；启动时将地址（sid， url）注册到push服务；push服务收到推送数据请求时，根据sid 发起 ZMQ.REQ 发起请求

   ```
   
                                   PUSH-SERVER
   
   connector1 PUSH ----->
   
   connector2 PUSH -----> PULL  GAME
   
   connector3 PUSH ----->
   ```

   

4. 架构三：采用zeromq，只能单个connector [最简单]

   ```shell
   connector PUSH -----> PULL  GAME
         
             PULL <----- PUSH  GAME 
   ```

   





## 2.4 服务划分为有状态和无状态

```

client ---- http ------>  无状态服务

                   connector1
                                 ws/zmq
client   ---->     connector2   -------->  有状态服务,比如玩法
               
                   connector3
```









# 第三章 基于GRPC的协议

推荐这种架构，比上面的zeromq要简单；zeromq安装依赖包有点麻烦，因为需要使用c语言的动态链接库和头文件。

1. game定义接口

   

   + send：connector调用此接口将数据包发送到game

   + register：connector 调用此接口将自己的地址注册到game，game就可以主动推送消息了(for循环推送给全部connector，connector自己过滤)

   + getSID：connector启动时，获取sID，唯一;可以存数据库里面

   + 数据包格式

     ```protobuf
     message Package
     {
     	int32 sID  = 1;
     	int32 cID  = 2;
     	bytes data = 3;
     }
     ```

2. 服务架构

   ```
   connector-1
   
   connector-2   GRPC---------> game
   
   connector-n
   ```

3. 要求更高的服务架构，登录的时候，把uid和过期时间用jwt加密到token里，就不需要Auth服务了

   ```
   
    client --------->            (http)Lolgin
   
   
   connector-1                                     财务服[管理金币、数据库操作]
                                [会话管理、推送信息]               |
   connector-2   GRPC---------> session ------> GRPC game[游戏逻辑,这里可以微服务(有状态/无状态)或者单服]
                                  |
   connector-n                   Auth [鉴权--无状态]
   ```
   
   





# 第四章 基于http的协议

这种解决方案的有点在于简单



1. 客户端通过http协议请求服务器数据，服务端有一个专门的推送服务，每个客户端和推送服务建立长连接
2. 客户端和服务器采用json格式通信，服务端推送给客户端的数据也是json
3. token的时间可以设置为1个月或者永远







# 第五章 连接服务的设计



## 5.1 采用云风的思路

云风的连接器没有业务，会更加通用

url = https://blog.codingnow.com/2006/04/iocp_kqueue_epoll.html



## 5.2 传统思路

传统思路相对云风的，会更加简洁。

1. client 访问login 返回token，jwt 会把 uid 和 过期时间戳加密放进token
2. connector 收到client登录请求时，解密得出uid，直接和socket 进行绑定





# 第六章 推送服务的设计

跑马灯、公告之类的需求，需要向部分/全部玩家推送数据，因此需要一个单独的推送服务。设计的时候，会把推送服务和session服务合并为一个。

1. client 拿token 连接connector时，会解密出uid和socket绑定，并且将 connectorAddr ：uid 信息注册到session，session如果发现其它地方登录，会调用connector的rpc将原来的用户踢下线

2. 其它请求直接转发到对应的服务，如果发其它请求之前，未发送登录请求，就找不到uid，直接丢包，非常简单

   ```shell
   1、每个链接会有一个localAddress   ip:port
   2、根据localAddress 查找对应uid
   3、如果找到了，转发给特定服务
   4、如果找不到，直接丢包
   ```



# 第六章  财务服务的设计

全部数据库相关的操作，全部封装到财务服务，做成无状态的



# 第七章 登录服务的设计

1. 协议采用http
2. 做成无状态的